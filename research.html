---
layout: page
title: Research
---

<h2 style="text-align:center">Projects</h2>
<hr style="height:1px;border:none;color:#333;background-color:#333;" />
<h3 style="text-align:center">HOnnotate: A method for 3D Annotation of Hand and Object Poses</h3>
<h4 style="text-align:center">
 <a href="http://shreyashampali.github.io/"> Shreyas Hampali,</a>
 <a href="https://www.tugraz.at/institute/icg/research/team-lepetit/people/mahdi-rad/"> Mahdi Rad,</a>
 <a href="https://www.tugraz.at/institute/icg/research/team-lepetit/people/markus-oberweger/"> Markus Oberweger,</a>
 <a href="https://www.labri.fr/perso/vlepetit/"> Vincent Lepetit</a>
</h4>
<h4 style="text-align:center"><i>In The IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2020</i></h4>
<p style="text-align:center;"><img src="/img/honnotate.png" alt="HOnnotate" width="1258"height="300"</p>
<p><b>Abstract</b>: We propose a method for annotating images of a hand manipulating an object with the 3D poses of both the hand and the object, together with a dataset created using this method. There is a current lack of annotated real images for this problem, as estimating the 3D poses is challenging, mostly because of the mutual occlusions between the hand and the object. To tackle this challenge, we capture sequences with one or several RGB-D cameras, and jointly optimizes the 3D hand and object poses over all the frames simultaneously. This method allows us to automatically annotate each frame with accurate estimates of the poses, despite large mutual occlusions. With this method, we created HO-3D, the first markerless dataset of color images with 3D annotations of both hand and object. This dataset is currently made of 80,000 frames, 65 sequences, 10 persons, and 10 objects. We also use it to train a deepnet to perform RGB-based single frame hand pose estimation and provide a baseline on our dataset.</p>
<p>[<a href="https://arxiv.org/abs/1907.01481">paper</a>] [<a href="https://drive.google.com/file/d/1FmJjSnr00IfUWRiJG_LVCpQUJETjmMY4/view?usp=sharing"> Supplementary</a>] [<a href="https://github.com/shreyashampali/HOnnotate"> Code</a>]</p>
<p><b>Dataset: </b>Please visit the <a href="https://www.tugraz.at/index.php?id=40231">project page</a> to download the dataset</p>
<p><b>CodaLab Competition: </b>Online challenge for hand pose estimation from single RGB image on our dataset <a href="https://competitions.codalab.org/competitions/22485?">here</a></p>
<p><b>Video:</b></p>
<p style="text-align:center;">
<iframe width="700" height="395" src="https://www.youtube.com/embed/S1acEA0U0hk?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
<hr style="height:1px;border:none;color:#333;background-color:#333;" />
<h3 style="text-align:center">General 3D Room Layout from a Single View by Render-and-Compare</h3>
<h4 style="text-align:center">
 <a href="https://www.tugraz.at/institute/icg/research/team-lepetit/people/sinisa-stekovic/"> Sinisa Stekovic,</a>
 <a href="http://shreyashampali.github.io/"> Shreyas Hampali,</a>
 <a href="https://www.tugraz.at/institute/icg/research/team-lepetit/people/mahdi-rad/"> Mahdi Rad,</a>
 <a href="https://www.tugraz.at/institute/icg/research/team-lepetit/people/sayan-deb-sarkar/"> Sayan Deb Sarkar,</a>
 <a href="https://www.tugraz.at/institutes/icg/research/team-fraundorfer/people/friedrich-fraundorfer/"> Friedrich Fraundorfer</a>
 <a href="https://www.labri.fr/perso/vlepetit/"> Vincent Lepetit</a>
</h4>
<h4 style="text-align:center"><i>In Proc. European Conference on Computer Vision (ECCV), 2020</i></h4>
<p>[<a href="https://arxiv.org/pdf/2001.02149.pdf">paper</a>] [<a href="https://files.icg.tugraz.at/f/4ebd05b88f0d4e00be07/?dl=1"> Supplementary</a>] [<a href="https://github.com/vevenom/ScanNet-Layout"> ScanNet-Layout Dataset</a>] [<a href="https://github.com/vevenom/RoomLayout3D_RandC"> Code</a>]</p>
<hr style="height:1px;border:none;color:#333;background-color:#333;" />

<h2 style="text-align:center">Patents</h2>
<hr style="height:1px;border:none;color:#333;background-color:#333;" />
<ol>
 <li><b>Shreyas Hampali</b>, “Video Coding Including a Stage-Interdependent Multi-Stage
Butterfly Integer Transform”, U.S. Patent 20160021369, published Jan 21, 2016.</li>
  <li><b>Shreyas Hampali</b>, Ajit Rao, Yogesh Gupta and Conrad Harrison, “Artifact detection
in a contrast enhanced output image”, U.S. Patent filed, Application no. 15/702,394</li>
 <li><b>Shreyas Hampali</b>, Pawan Baheti and Naveen Srinivasamurthy, “Systems and methods for non-recursive image signal processor tuning using a reference
image”, India Patent filed, Application no. 201841003400</li>
 <li>Shilpi Sahi, Pawan Baheti, Aarrushi Shandilya, <b>Shreyas Hampali</b>,
Naveen Srinivasamurthy and Yogesh Gupta, “Systems and methods for assisted image signal processor tuning”, India Patent filed, Application no. 201841003395</li>
 <li>Pawan Baheti, Shilpi Sahu, Naveen Srinivasamurthy, Yogesh Gupta, Uday Kiran
Pudipeddi, <b>Shreyas Hampali</b>, “Systems and methods for assisted
image signal processor tuning using a reference image”, India patent filed, Application no. 201841003373</li>
 <li><b>Shreyas Hampali</b> and Dowray Raghvendra Rao, ”Remote Image based Measurement
System”, India Patent 4785/CHE/2012, filed November 2012.</li>
</ol>
<hr style="height:1px;border:none;color:#333;background-color:#333;" />

