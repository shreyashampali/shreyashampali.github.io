---
layout: page
title: Research
---

<h2 style="text-align:center">Projects</h2>
<hr/>
<h3 style="text-align:center">HOnnotate: A method for 3D Annotation of Hand and Objects Poses</h3>
<img src="/img/honnotateImg.png" alt="HOnnotate" width="200"height="80">
<p><b>Abstarct</b>: We propose a method for annotating images of a hand
manipulating an object with the 3D poses of both the hand
and the object, together with a dataset created using this
method. There is a current lack of annotated real images
for this problem, as estimating the 3D poses is challeng-
ing, mostly because of the mutual occlusions between the
hand and the object. To tackle this challenge, we capture
sequences with one or several RGB-D cameras, and jointly
optimizes the 3D hand and object poses over all the frames
simultaneously. This method allows us to automatically an-
notate each frame with accurate estimates of the poses, de-
spite large mutual occlusions. With this method, we created
HO-3D, the first markerless dataset of color images with
3D annotations of both hand and object. This dataset is
currently made of 80,000 frames, 65 sequences, 10 persons,
and 10 objects, and growing, and we will make it publicly
available upon publication. We also use it to train a deepnet
to perform RGB-based single frame hand pose estimation
  and provide a baseline on our dataset.</p>
<p><b>Preprint: </b></p>
<p><b>Data: </b></p>
<p><b>Code: </b></p>
<hr/>
